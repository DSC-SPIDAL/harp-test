<!DOCTYPE html><html lang="en-us"><head><link rel="shortcut icon" type="image/png" sizes="16x16" href="https://dsc-spidal.github.io/harp-test/img/favicon-16x9.png"><link rel="shortcut icon" type="image/png" sizes="32x32" href="https://dsc-spidal.github.io/harp-test/img/favicon-32x18.png"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Hugo 0.18" /><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="harp"><meta property="og:image" content="/img/logo54x54.png"><meta property="og:url" content="https://dsc-spidal.github.io/harp-test/"><meta name="twitter:title" content="harp"><meta name="twitter:image" content="/img/0-1-1.png"><meta property="og:site_name" content="Quick Start Guide"><meta property="og:url" content="/docs/getting-started-cluster/"><meta property="og:description" content="Run multi-node Harp on clusters"><meta name="twitter:description" content="Run multi-node Harp on clusters"><title>harp Documentation - Quick Start Guide</title><link rel="stylesheet" href="https://dsc-spidal.github.io/harp-test/css/style.min.css"><link rel="stylesheet" href="https://dsc-spidal.github.io/harp-test/css/font-awesome.min.css"><link rel="stylesheet" href="https://dsc-spidal.github.io/harp-test/css/pygments.css"></head><body><nav class="hn-top-navbar navbar navbar-inverse navbar-fixed-top" role="navigation"><div class="hn-navbar-container container-fluid"><div class="navbar-header"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#hn-navbar" aria-controls="hn-navbar" aria-expanded="false"><span class="sr-only"><Toggle>navigation</Toggle></span><i class="hn-toggle-button fa fa-bars"></i></button><a class="hn-navbar-logo navbar-brand" href="https://dsc-spidal.github.io/harp-test/"><img class="pull-left" src="https://dsc-spidal.github.io/harp-test/img/0-1-2.png" width="62%"></a></div><div id="hn-navbar" class="navbar-collapse collapse"><ul class="nav navbar-nav navbar-right"><li><a href="https://dsc-spidal.github.io/harp-test/docs/getting-started">Docs</a></li><li><a href="https://dsc-spidal.github.io/harp-test/api">API</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/resources">Resources</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/contributors/community">Community</a></li><li><a href="https://github.com/DSC-SPIDAL/harp-test/">GitHub</a></li><li><a href="https://groups.google.com/forum/#!forum/harp-users">Mailing List</a></li></ul></div></div></nav><div class="hn-main"><div class="container"><div class="row"><aside class="hn-sidebar hidden-xs col-sm-4 col-md-3 col-lg-2 collapse"><nav class="hn-sidebar-nav"><div id="hn-accordion" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="quick-start" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-quick-start" aria-labelledby="quick-start"><i class="fa fa-caret-right"></i>Quick Start</a></h4></section><div id="collapse-quick-start" class="panel-collapse collapse" aria-labelledby="quick-start"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp-test/docs/getting-started">Harp Installation (single)</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/getting-started-cluster">Harp Installation (cluster)</a></li></ul></div></div></div><div class="panel panel-default"><section id="programming-guides" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-programming-guides" aria-labelledby="programming-guides"><i class="fa fa-caret-right"></i>Programming Guides</a></h4></section><div id="collapse-programming-guides" class="panel-collapse collapse" aria-labelledby="programming-guides"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp-test/docs/programming/overview">Overview</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/programming/data-interface">Data Interfaces and Types</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/programming/scheduler">Schedulers</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/programming/computation-models">Computation Models</a></li></ul></div></div></div><div class="panel panel-default"><section id="collective-communication" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-collective-communication" aria-labelledby="collective-communication"><i class="fa fa-caret-right"></i>Collective Communication</a></h4></section><div id="collapse-collective-communication" class="panel-collapse collapse" aria-labelledby="collective-communication"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp-test/docs/communications/broadcast">broadcast</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/communications/reduce">reduce</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/communications/allgather">allgather</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/communications/allreduce">allreduce</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/communications/regroup">regroup</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/communications/pushandpull">push &amp; pull</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/communications/rotate">rotate</a></li></ul></div></div></div><div class="panel panel-default"><section id="examples" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-examples" aria-labelledby="examples"><i class="fa fa-caret-right"></i>Examples</a></h4></section><div id="collapse-examples" class="panel-collapse collapse" aria-labelledby="examples"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp-test/docs/examples/overview">Overview</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/examples/kmeans">K-Means</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/examples/mlrsgd">Multiclass Logistic Regression</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/examples/lda">Latent Dirichlet Allocation (CVB)</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/examples/svm">Support Vector Machine</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/examples/rf">Random Forests</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/examples/nn">Neural Network</a></li></ul></div></div></div><div class="panel panel-default"><section id="applications" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-applications" aria-labelledby="applications"><i class="fa fa-caret-right"></i>Applications</a></h4></section><div id="collapse-applications" class="panel-collapse collapse" aria-labelledby="applications"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp-test/docs/applications/lda-cgs">Latent Dirichlet Allocation (CGS)</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/applications/mf">Matrix Factorization</a></li></ul></div></div></div><div class="panel panel-default"><section id="harp-daal" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-harp-daal" aria-labelledby="harp-daal"><i class="fa fa-caret-right"></i>Harp-DAAL</a></h4></section><div id="collapse-harp-daal" class="panel-collapse collapse" aria-labelledby="harp-daal"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp-test/docs/harpdaal/harpdaal">Overview</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/harpdaal/mfsgd">Matrix Factorization (SGD)</a></li></ul></div></div></div><div class="panel panel-default"><section id="harp-resources" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-harp-resources" aria-labelledby="harp-resources"><i class="fa fa-caret-right"></i>Harp Resources</a></h4></section><div id="collapse-harp-resources" class="panel-collapse collapse" aria-labelledby="harp-resources"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp-test/docs/resources">Harp Resources</a></li></ul></div></div></div><div class="panel panel-default"><section id="contributors" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-contributors" aria-labelledby="contributors"><i class="fa fa-caret-right"></i>Contributors</a></h4></section><div id="collapse-contributors" class="panel-collapse collapse" aria-labelledby="contributors"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp-test/docs/contributors/community">Community</a></li><li><a href="https://dsc-spidal.github.io/harp-test/docs/contributors/contributors">Contributors</a></li></ul></div></div></div></div></nav></aside><section class="hn-docs-main col-sm-8 col-md-9 col-lg-10 col-sm-offset-4 col-md-offset-3 col-lg-offset-2"><header class="hn-docs-header page-header"><h1>Quick Start Guide</h1><div class="hn-docs-description">Run multi-node Harp on clusters</div></header><article class="hn-docs-content">

<p>These instructions have only been tested on:</p>

<ul>
<li>Red Hat Enterprise Linux Server release 6.8</li>
</ul>

<h2 id="step-1-install-hadoop-2-6-0">Step 1 &mdash; Install Hadoop 2.6.0</h2>

<ol>
<li><p>Make sure your computer can use <code>ssh</code> to access each node in the cluster and can install <code>Java</code> as well.</p></li>

<li><p>Download and extract the hadoop-2.6.0 binary into your machine. It&rsquo;s available at <a href="https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz">hadoop-2.6.0.tar.gz</a>.</p></li>

<li><p>Set the environment variables in <code>~/.bashrc</code>.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span><span class="nb">export</span> <span class="nv">JAVA_HOME</span><span class="o">=</span>&lt;where Java locates&gt;
<span class="c1">#e.g. ~/jdk1.8.0_91</span>
<span class="nb">export</span> <span class="nv">HADOOP_HOME</span><span class="o">=</span>&lt;where hadoop-2.6.0 locates&gt;
<span class="c1">#e.g. ~/hadoop-2.6.0</span>
<span class="nb">export</span> <span class="nv">YARN_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>/bin:<span class="nv">$JAVA_HOME</span>/bin:<span class="nv">$PATH</span>
<span class="nb">source</span> <span class="nv">$HADOOP_HOME</span>/etc/hadoop/hadoop-env.sh
<span class="nb">export</span> <span class="nv">HADOOP_CONF_DIR</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>/etc/hadoop
<span class="nb">export</span> <span class="nv">HADOOP_MAPRED_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export</span> <span class="nv">HADOOP_COMMON_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export</span> <span class="nv">HADOOP_HDFS_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export</span> <span class="nv">HADOOP_YARN_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export</span> <span class="nv">HADOOP_COMMON_LIB_NATIVE_DIR</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>/lib/native
</code></pre></div></li>

<li><p>Run to test if the changes are applied.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ <span class="nb">source</span> ~/.bashrc
</code></pre></div></li>

<li><p>Check if environment variabls are set correctly.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ hadoop
Usage: hadoop <span class="o">[</span>--config confdir<span class="o">]</span> COMMAND
   where COMMAND is one of:
fs                   run a generic filesystem user client
version              print the version
jar &lt;jar&gt;            run a jar file
checknative <span class="o">[</span>-a<span class="p">|</span>-h<span class="o">]</span>  check native hadoop and compression libraries availability
distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively
archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive
classpath            prints the class path needed to get the
credential           interact with credential providers
                   Hadoop jar and the required libraries
daemonlog            get/set the log level <span class="k">for</span> each daemon
trace                view and modify Hadoop tracing settings
or
CLASSNAME            run the class named CLASSNAME
Most commands print <span class="nb">help</span> when invoked w/o parameters.
</code></pre></div></li>

<li><p>Modify the following files in Apache Hadoop distribution:</p>

<p>(1).<code>$HADOOP_HOME/etc/hadoop/core-site.xml</code>:</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span></span><span class="nt">&lt;configuration&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>fs.default.name<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>hdfs://${namenode}:9010<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>hadoop.tmp.dir<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>/tmp/hadoop-${user name}<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;description&gt;</span>A base for other temporary directories.<span class="nt">&lt;/description&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>

<p>(2).<code>$HADOOP_HOME/etc/hadoop/hdfs-site.xml</code>:</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span></span><span class="nt">&lt;configuration&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>dfs.hosts<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>${HADOOP_HOME}/etc/hadoop/slaves<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>dfs.namenode.http-address<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>${namenode}:50271<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>dfs.namenode.secondary.http-address<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>${namenode}:50291<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>

<p>(3).<code>$HADOOP_HOME/etc/hadoop/mapred-site.xml</code>:
You will be creating this file. It doesn’t exist in the original package.</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span></span><span class="nt">&lt;configuration&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>mapreduce.framework.name<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>yarn<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>mapreduce.map.collective.memory.mb<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>100000<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>mapreduce.map.collective.java.opts<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>-Xmx90000m -Xms90000m<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>

<p>(4).<code>$HADOOP_HOME/etc/hadoop/yarn-site.xml</code>:</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span></span><span class="nt">&lt;configuration&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>yarn.resourcemanager.hostname<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>${namenode}<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>yarn.resourcemanager.address<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>${namenode}:8132<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>yarn.resourcemanager.scheduler.address<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>${namenode}:8230<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>yarn.nodemanager.log-dirs<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>/tmp/hadoop-${user name}<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>128000<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>yarn.nodemanager.resource.memory-mb<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>120000<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>yarn.nodemanager.delete.debug-delay-sec<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>10000000<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>

<p>(5).<code>$HADOOP_HOME/etc/hadoop/slaves</code>:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span><span class="si">${</span><span class="nv">namenode</span><span class="si">}</span>
<span class="si">${</span><span class="nv">other</span><span class="p"> node 1</span><span class="si">}</span>
<span class="si">${</span><span class="nv">other</span><span class="p"> node 2</span><span class="si">}</span>
...
</code></pre></div></li>

<li><p>Format the file system and you should be able to see it exits with status 0.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ hdfs namenode -format
...
xx/xx/xx xx:xx:xx INFO util.ExitUtil: Exiting with status <span class="m">0</span>
xx/xx/xx xx:xx:xx INFO namenode.NameNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at xxx.xxx.xxx.xxx
</code></pre></div></li>

<li><p>Launch NameNode daemon, DataNode daemon, ResourceManager daemon and NodeManager Daemon.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ <span class="nv">$HADOOP_HOME</span>/sbin/start-dfs.sh
$ <span class="nv">$HADOOP_HOME</span>/sbin/start-yarn.sh
</code></pre></div></li>

<li><p>Check if the daemons started successfully with the following output:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ jps
xxxxx NameNode
xxxxx SecondaryNameNode
xxxxx DataNode
xxxxx NodeManager
xxxxx Jps
xxxxx ResourceManager
</code></pre></div></li>
</ol>

<h2 id="step-2-install-harp">Step 2 &mdash; Install Harp</h2>

<ol>
<li><p>Clone Harp repository. It is available at <a href="https://github.com/DSC-SPIDAL/harp.git">DSC-SPIDAL/harp</a>.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ git clone git@github.com:DSC-SPIDAL/harp.git
</code></pre></div></li>

<li><p>Follow the <a href="http://maven.apache.org/install.html">maven official instruction</a> to install maven.</p></li>

<li><p>Add environment variables in <code>~/.bashrc</code>.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span><span class="nb">export</span> <span class="nv">HARP_ROOD_DIR</span><span class="o">=</span>&lt;where Harp locates&gt;
<span class="c1">#e.g. harp/harp-project</span>
<span class="nb">export</span> <span class="nv">HARP_HOME</span><span class="o">=</span><span class="nv">$HARP_ROOD_DIR</span>/harp-project
</code></pre></div></li>

<li><p>Run source command to set the envrionment variables.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ <span class="nb">source</span> ~/.bashrc
</code></pre></div></li>

<li><p>Stop hadoop first if it is still running.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ <span class="nv">$HADOOP_HOME</span>/sbin/stop-dfs.sh
$ <span class="nv">$HADOOP_HOME</span>/sbin/stop-yarn.sh
</code></pre></div></li>

<li><p>Enter &ldquo;harp&rdquo; home directory.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ <span class="nb">cd</span> <span class="nv">$HARP_ROOT_DIR</span>
</code></pre></div></li>

<li><p>Compile harp.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ mvn clean package
</code></pre></div></li>

<li><p>Install harp plugin to hadoop.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ cp harp-project/target/harp-project-1.0-SNAPSHOT.jar <span class="nv">$HADOOP_HOME</span>/share/hadoop/mapreduce/
$ cp third_party/fastutil-7.0.13.jar <span class="nv">$HADOOP_HOME</span>/share/hadoop/mapreduce/
</code></pre></div></li>

<li><p>Edit mapred-site.xml in $HADOOP_HOME/etc/hadoop, add java opts settings for map-collective tasks. For example:</p>
<div class="highlight"><pre><code class="language-xml" data-lang="xml"><span></span><span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>mapreduce.map.collective.memory.mb<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>512<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
<span class="nt">&lt;name&gt;</span>mapreduce.map.collective.java.opts<span class="nt">&lt;/name&gt;</span>
<span class="nt">&lt;value&gt;</span>-Xmx256m -Xms256m<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div></li>

<li><p>To develop Harp applications, remember to add the following property in job configuration:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>jobConf.set<span class="o">(</span><span class="s2">&quot;mapreduce.framework.name&quot;</span>, <span class="s2">&quot;map-collective&quot;</span><span class="o">)</span><span class="p">;</span>
</code></pre></div></li>
</ol>

<h2 id="step-3-run-harp-kmeans-example">Step 3 Run harp kmeans example</h2>

<ol>
<li><p>Format datanode in other nodes.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ ssh <span class="si">${</span><span class="nv">other</span><span class="p"> nodes</span><span class="si">}</span>
$ hadoop datanode -format
</code></pre></div>

<p>You have to do this step in every node except the namenode.</p></li>

<li><p>Copy harp examples to <code>$HADOOP_HOME</code>.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ cp harp-app/target/harp-app-1.0-SNAPSHOT.jar <span class="nv">$HADOOP_HOME</span>
</code></pre></div></li>

<li><p>Start Hadoop.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ <span class="nb">cd</span> <span class="nv">$HADOOP_HOME</span>
$ sbin/start-dfs.sh
$ sbin/start-yarn.sh
</code></pre></div></li>

<li><p>Check and see if other nodes work as well. This output will only appear in datanode.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ jps
xxxxx DataNode
xxxxx NodeManager
xxxxx Jps
</code></pre></div></li>

<li><p>To view your running applications in terminal, use:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ yarn application -list
</code></pre></div></li>

<li><p>To shutdown a running application, use:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ yarn application -kill application-id
</code></pre></div></li>

<li><p>Run Kmeans Map-collective job. The usage is:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ hadoop jar harp-app-1.0-SNAPSHOT.jar edu.iu.kmeans.regroupallgather.KMeansLauncher &lt;num of points&gt; &lt;num of centroids&gt; &lt;vector size&gt; &lt;num of point files per worker&gt; &lt;number of map tasks&gt; &lt;num threads&gt; &lt;number of iteration&gt; &lt;work dir&gt; &lt;<span class="nb">local</span> points dir&gt;
<span class="c1">#e.g. hadoop jar harp-app-1.0-SNAPSHOT.jar edu.iu.kmeans.regroupallgather.KMeansLauncher 1000 10 100 5 2 2 10 /kmeans /tmp/kmeans</span>
</code></pre></div>

<ul>
<li><code>&lt;num of points&gt;</code> &mdash; the number of data points you want to generate randomly</li>
<li><code>&lt;num of centriods&gt;</code> &mdash; the number of centroids you want to clustering the data to</li>
<li><code>&lt;vector size&gt;</code> &mdash; the number of dimension of the data</li>
<li><code>&lt;num of point files per worker&gt;</code> &mdash; how many files which contain data points in each worker</li>
<li><code>&lt;number of map tasks&gt;</code> &mdash; number of map tasks</li>
<li><code>&lt;num threads&gt;</code> &mdash; how many threads to launch in each worker</li>
<li><code>&lt;number of iteration&gt;</code> &mdash; the number of iterations to run</li>
<li><code>&lt;work dir&gt;</code> &mdash; the root directory for this running in HDFS</li>
<li><code>&lt;local points dir&gt;</code> &mdash; the harp kmeans will firstly generate files which contain data points to local directory. Set this argument to determine the local directory.</li>
</ul></li>

<li><p>To fetch the results, use the following command:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>$ hdfs dfs –get &lt;work dir&gt; &lt;<span class="nb">local</span> dir&gt;
<span class="c1">#e.g. hdfs dfs -get /kmeans ~/Document</span>
</code></pre></div></li>
</ol>
</article></section></div></div></div><script src="https://code.jquery.com/jquery-2.2.1.min.js"></script><script src="https://dsc-spidal.github.io/harp-test/js/app.min.js"></script></body></html>